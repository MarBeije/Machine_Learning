{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import shuffle \n",
    "from sklearn.datasets import load_files\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SimpleRNN\n",
    "\n",
    "#import tflearn\n",
    "#from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "#from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "#from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"SkinData/train\"\n",
    "TEST_DIR = \"SkinData/test\"\n",
    "CATEGORIES = [\"benign\",\"malignant\"]\n",
    "\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3 \n",
    "MODEL_NAME = \"malignant_benign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign 0\n",
      "malignant 1\n"
     ]
    }
   ],
   "source": [
    "def labels():\n",
    "    for category in CATEGORIES:\n",
    "        num = CATEGORIES.index(category)\n",
    "        print(category, num)\n",
    "        \n",
    "labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for category in CATEGORIES:  \n",
    "        path = os.path.join(TRAIN_DIR,category)  # create path to benign and malignant\n",
    "        class_num = CATEGORIES.index(category)    \n",
    "        \n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per category\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "            training_data.append([np.array(new_array), class_num])\n",
    "        \n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1440/1440 [00:21<00:00, 66.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1197/1197 [00:19<00:00, 61.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2637\n"
     ]
    }
   ],
   "source": [
    "#train_data = create_training_data()\n",
    "train_data = np.load('train_data.npy')\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in train_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "    \n",
    "X_train = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Y_train = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('features.npy',X) #saving\n",
    "np.save('label.npy',Y) #saving\n",
    "X=np.load('label.npy')#loading\n",
    "Y=np.load('features.npy')#loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 59,969\n",
      "Trainable params: 59,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(50,50,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1845 samples, validate on 792 samples\n",
      "Epoch 1/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 3.8562 - accuracy: 0.75 - ETA: 1s - loss: 5.3023 - accuracy: 0.65 - ETA: 1s - loss: 5.8808 - accuracy: 0.61 - ETA: 1s - loss: 6.5418 - accuracy: 0.57 - ETA: 1s - loss: 6.4271 - accuracy: 0.58 - ETA: 1s - loss: 6.7046 - accuracy: 0.56 - ETA: 1s - loss: 6.7855 - accuracy: 0.56 - ETA: 1s - loss: 6.8448 - accuracy: 0.55 - ETA: 1s - loss: 7.0320 - accuracy: 0.54 - ETA: 1s - loss: 7.1290 - accuracy: 0.53 - ETA: 1s - loss: 7.2534 - accuracy: 0.52 - ETA: 1s - loss: 7.2095 - accuracy: 0.53 - ETA: 1s - loss: 7.1340 - accuracy: 0.53 - ETA: 1s - loss: 7.1377 - accuracy: 0.53 - ETA: 1s - loss: 7.1616 - accuracy: 0.53 - ETA: 1s - loss: 7.3136 - accuracy: 0.52 - ETA: 0s - loss: 7.2926 - accuracy: 0.52 - ETA: 0s - loss: 7.2597 - accuracy: 0.52 - ETA: 0s - loss: 7.2855 - accuracy: 0.52 - ETA: 0s - loss: 7.2174 - accuracy: 0.53 - ETA: 0s - loss: 7.1810 - accuracy: 0.53 - ETA: 0s - loss: 7.1364 - accuracy: 0.53 - ETA: 0s - loss: 7.1183 - accuracy: 0.53 - ETA: 0s - loss: 7.1209 - accuracy: 0.53 - ETA: 0s - loss: 7.0942 - accuracy: 0.54 - ETA: 0s - loss: 7.1200 - accuracy: 0.53 - ETA: 0s - loss: 7.0473 - accuracy: 0.54 - ETA: 0s - loss: 7.0636 - accuracy: 0.54 - ETA: 0s - loss: 7.0576 - accuracy: 0.54 - ETA: 0s - loss: 7.0815 - accuracy: 0.54 - ETA: 0s - loss: 7.1036 - accuracy: 0.53 - 2s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 2/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 6.7484 - accuracy: 0.56 - ETA: 2s - loss: 7.3911 - accuracy: 0.52 - ETA: 2s - loss: 7.0376 - accuracy: 0.54 - ETA: 1s - loss: 7.0239 - accuracy: 0.54 - ETA: 1s - loss: 7.0162 - accuracy: 0.54 - ETA: 1s - loss: 7.1428 - accuracy: 0.53 - ETA: 1s - loss: 7.4158 - accuracy: 0.51 - ETA: 1s - loss: 7.3590 - accuracy: 0.52 - ETA: 1s - loss: 7.2872 - accuracy: 0.52 - ETA: 1s - loss: 7.1036 - accuracy: 0.53 - ETA: 1s - loss: 7.0239 - accuracy: 0.54 - ETA: 1s - loss: 7.0209 - accuracy: 0.54 - ETA: 1s - loss: 7.0569 - accuracy: 0.54 - ETA: 1s - loss: 6.9627 - accuracy: 0.54 - ETA: 0s - loss: 6.9977 - accuracy: 0.54 - ETA: 0s - loss: 6.9195 - accuracy: 0.55 - ETA: 0s - loss: 7.0406 - accuracy: 0.54 - ETA: 0s - loss: 7.0376 - accuracy: 0.54 - ETA: 0s - loss: 7.1262 - accuracy: 0.53 - ETA: 0s - loss: 7.1439 - accuracy: 0.53 - ETA: 0s - loss: 7.1952 - accuracy: 0.53 - ETA: 0s - loss: 7.1856 - accuracy: 0.53 - ETA: 0s - loss: 7.1769 - accuracy: 0.53 - ETA: 0s - loss: 7.1990 - accuracy: 0.53 - ETA: 0s - loss: 7.2099 - accuracy: 0.53 - ETA: 0s - loss: 7.2009 - accuracy: 0.53 - ETA: 0s - loss: 7.2115 - accuracy: 0.53 - ETA: 0s - loss: 7.2123 - accuracy: 0.53 - ETA: 0s - loss: 7.1691 - accuracy: 0.53 - ETA: 0s - loss: 7.1290 - accuracy: 0.53 - 2s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 3/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 10.1226 - accuracy: 0.343 - ETA: 2s - loss: 7.7125 - accuracy: 0.500 - ETA: 2s - loss: 7.1340 - accuracy: 0.53 - ETA: 2s - loss: 7.6436 - accuracy: 0.50 - ETA: 1s - loss: 7.6054 - accuracy: 0.50 - ETA: 1s - loss: 7.8001 - accuracy: 0.49 - ETA: 1s - loss: 7.7496 - accuracy: 0.49 - ETA: 1s - loss: 7.5403 - accuracy: 0.51 - ETA: 1s - loss: 7.2606 - accuracy: 0.52 - ETA: 1s - loss: 7.2037 - accuracy: 0.53 - ETA: 1s - loss: 7.1036 - accuracy: 0.53 - ETA: 1s - loss: 7.0698 - accuracy: 0.54 - ETA: 1s - loss: 7.0837 - accuracy: 0.54 - ETA: 1s - loss: 7.0376 - accuracy: 0.54 - ETA: 1s - loss: 6.9448 - accuracy: 0.54 - ETA: 1s - loss: 6.9811 - accuracy: 0.54 - ETA: 1s - loss: 7.0128 - accuracy: 0.54 - ETA: 0s - loss: 6.9383 - accuracy: 0.55 - ETA: 0s - loss: 6.9825 - accuracy: 0.54 - ETA: 0s - loss: 7.0741 - accuracy: 0.54 - ETA: 0s - loss: 7.1192 - accuracy: 0.53 - ETA: 0s - loss: 7.0497 - accuracy: 0.54 - ETA: 0s - loss: 7.0353 - accuracy: 0.54 - ETA: 0s - loss: 7.0399 - accuracy: 0.54 - ETA: 0s - loss: 7.0990 - accuracy: 0.53 - ETA: 0s - loss: 7.0805 - accuracy: 0.54 - ETA: 0s - loss: 7.0523 - accuracy: 0.54 - ETA: 0s - loss: 7.0663 - accuracy: 0.54 - ETA: 0s - loss: 7.0597 - accuracy: 0.54 - ETA: 0s - loss: 7.0280 - accuracy: 0.54 - ETA: 0s - loss: 7.0358 - accuracy: 0.54 - ETA: 0s - loss: 7.0698 - accuracy: 0.54 - ETA: 0s - loss: 7.0841 - accuracy: 0.54 - ETA: 0s - loss: 7.1205 - accuracy: 0.53 - 3s 2ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 4/10\n",
      "1845/1845 [==============================] - ETA: 1s - loss: 9.1586 - accuracy: 0.40 - ETA: 2s - loss: 7.5518 - accuracy: 0.51 - ETA: 1s - loss: 6.9412 - accuracy: 0.55 - ETA: 2s - loss: 6.6681 - accuracy: 0.56 - ETA: 1s - loss: 6.9292 - accuracy: 0.55 - ETA: 1s - loss: 6.8930 - accuracy: 0.55 - ETA: 1s - loss: 6.8288 - accuracy: 0.55 - ETA: 1s - loss: 6.8173 - accuracy: 0.55 - ETA: 1s - loss: 6.9292 - accuracy: 0.55 - ETA: 1s - loss: 7.0698 - accuracy: 0.54 - ETA: 1s - loss: 7.0617 - accuracy: 0.54 - ETA: 1s - loss: 7.0333 - accuracy: 0.54 - ETA: 1s - loss: 7.0418 - accuracy: 0.54 - ETA: 1s - loss: 7.0095 - accuracy: 0.54 - ETA: 1s - loss: 7.1007 - accuracy: 0.53 - ETA: 1s - loss: 7.1769 - accuracy: 0.53 - ETA: 1s - loss: 7.1960 - accuracy: 0.53 - ETA: 1s - loss: 7.2144 - accuracy: 0.53 - ETA: 1s - loss: 7.2455 - accuracy: 0.53 - ETA: 0s - loss: 7.3297 - accuracy: 0.52 - ETA: 0s - loss: 7.3406 - accuracy: 0.52 - ETA: 0s - loss: 7.2974 - accuracy: 0.52 - ETA: 0s - loss: 7.2431 - accuracy: 0.53 - ETA: 0s - loss: 7.3389 - accuracy: 0.52 - ETA: 0s - loss: 7.2892 - accuracy: 0.52 - ETA: 0s - loss: 7.2192 - accuracy: 0.53 - ETA: 0s - loss: 7.1983 - accuracy: 0.53 - ETA: 0s - loss: 7.1894 - accuracy: 0.53 - ETA: 0s - loss: 7.1601 - accuracy: 0.53 - ETA: 0s - loss: 7.1244 - accuracy: 0.53 - ETA: 0s - loss: 7.1192 - accuracy: 0.53 - ETA: 0s - loss: 7.1769 - accuracy: 0.53 - ETA: 0s - loss: 7.1616 - accuracy: 0.53 - 3s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 5/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 5.7844 - accuracy: 0.62 - ETA: 1s - loss: 6.5877 - accuracy: 0.57 - ETA: 2s - loss: 6.2664 - accuracy: 0.59 - ETA: 2s - loss: 6.4271 - accuracy: 0.58 - ETA: 1s - loss: 6.9894 - accuracy: 0.54 - ETA: 1s - loss: 6.9412 - accuracy: 0.55 - ETA: 1s - loss: 6.9675 - accuracy: 0.54 - ETA: 1s - loss: 7.1192 - accuracy: 0.53 - ETA: 1s - loss: 7.2649 - accuracy: 0.52 - ETA: 1s - loss: 7.2907 - accuracy: 0.52 - ETA: 1s - loss: 7.2037 - accuracy: 0.53 - ETA: 1s - loss: 7.2304 - accuracy: 0.53 - ETA: 1s - loss: 7.1428 - accuracy: 0.53 - ETA: 1s - loss: 7.2095 - accuracy: 0.53 - ETA: 1s - loss: 7.2304 - accuracy: 0.53 - ETA: 1s - loss: 7.2126 - accuracy: 0.53 - ETA: 1s - loss: 7.1788 - accuracy: 0.53 - ETA: 1s - loss: 7.1340 - accuracy: 0.53 - ETA: 0s - loss: 7.1401 - accuracy: 0.53 - ETA: 0s - loss: 7.1737 - accuracy: 0.53 - ETA: 0s - loss: 7.0296 - accuracy: 0.54 - ETA: 0s - loss: 7.0021 - accuracy: 0.54 - ETA: 0s - loss: 6.9774 - accuracy: 0.54 - ETA: 0s - loss: 7.0698 - accuracy: 0.54 - ETA: 0s - loss: 7.1099 - accuracy: 0.53 - ETA: 0s - loss: 7.1047 - accuracy: 0.53 - ETA: 0s - loss: 7.1099 - accuracy: 0.53 - ETA: 0s - loss: 7.0955 - accuracy: 0.54 - ETA: 0s - loss: 7.1076 - accuracy: 0.53 - ETA: 0s - loss: 7.1031 - accuracy: 0.53 - ETA: 0s - loss: 7.1340 - accuracy: 0.53 - ETA: 0s - loss: 7.1358 - accuracy: 0.53 - 2s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845/1845 [==============================] - ETA: 2s - loss: 5.3023 - accuracy: 0.65 - ETA: 2s - loss: 6.1057 - accuracy: 0.60 - ETA: 2s - loss: 6.7484 - accuracy: 0.56 - ETA: 1s - loss: 6.4730 - accuracy: 0.58 - ETA: 1s - loss: 6.5342 - accuracy: 0.57 - ETA: 1s - loss: 6.4855 - accuracy: 0.57 - ETA: 1s - loss: 6.6001 - accuracy: 0.57 - ETA: 1s - loss: 6.8127 - accuracy: 0.55 - ETA: 1s - loss: 6.8902 - accuracy: 0.55 - ETA: 1s - loss: 7.1036 - accuracy: 0.53 - ETA: 1s - loss: 7.0698 - accuracy: 0.54 - ETA: 1s - loss: 7.0628 - accuracy: 0.54 - ETA: 1s - loss: 7.1340 - accuracy: 0.53 - ETA: 1s - loss: 7.1412 - accuracy: 0.53 - ETA: 1s - loss: 7.1640 - accuracy: 0.53 - ETA: 0s - loss: 7.1060 - accuracy: 0.53 - ETA: 0s - loss: 7.1866 - accuracy: 0.53 - ETA: 0s - loss: 7.2167 - accuracy: 0.53 - ETA: 0s - loss: 7.1262 - accuracy: 0.53 - ETA: 0s - loss: 7.1439 - accuracy: 0.53 - ETA: 0s - loss: 7.0658 - accuracy: 0.54 - ETA: 0s - loss: 7.0959 - accuracy: 0.54 - ETA: 0s - loss: 7.1019 - accuracy: 0.53 - ETA: 0s - loss: 7.0869 - accuracy: 0.54 - ETA: 0s - loss: 7.1200 - accuracy: 0.53 - ETA: 0s - loss: 7.0955 - accuracy: 0.54 - ETA: 0s - loss: 7.1192 - accuracy: 0.53 - ETA: 0s - loss: 7.0965 - accuracy: 0.53 - ETA: 0s - loss: 7.1013 - accuracy: 0.53 - 2s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 7/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 6.2664 - accuracy: 0.59 - ETA: 2s - loss: 6.2664 - accuracy: 0.59 - ETA: 2s - loss: 6.6279 - accuracy: 0.57 - ETA: 1s - loss: 6.8288 - accuracy: 0.55 - ETA: 1s - loss: 6.8087 - accuracy: 0.55 - ETA: 1s - loss: 6.7002 - accuracy: 0.56 - ETA: 1s - loss: 6.8689 - accuracy: 0.55 - ETA: 1s - loss: 6.7484 - accuracy: 0.56 - ETA: 1s - loss: 6.8517 - accuracy: 0.55 - ETA: 1s - loss: 6.7484 - accuracy: 0.56 - ETA: 1s - loss: 6.6949 - accuracy: 0.56 - ETA: 1s - loss: 6.7992 - accuracy: 0.55 - ETA: 1s - loss: 6.7243 - accuracy: 0.56 - ETA: 1s - loss: 6.7714 - accuracy: 0.56 - ETA: 1s - loss: 6.9161 - accuracy: 0.55 - ETA: 1s - loss: 6.9219 - accuracy: 0.55 - ETA: 1s - loss: 6.8377 - accuracy: 0.55 - ETA: 1s - loss: 6.8980 - accuracy: 0.55 - ETA: 1s - loss: 6.9661 - accuracy: 0.54 - ETA: 0s - loss: 7.0552 - accuracy: 0.54 - ETA: 0s - loss: 7.1312 - accuracy: 0.53 - ETA: 0s - loss: 7.0698 - accuracy: 0.54 - ETA: 0s - loss: 7.0611 - accuracy: 0.54 - ETA: 0s - loss: 7.0909 - accuracy: 0.54 - ETA: 0s - loss: 7.1702 - accuracy: 0.53 - ETA: 0s - loss: 7.1386 - accuracy: 0.53 - ETA: 0s - loss: 7.1071 - accuracy: 0.53 - ETA: 0s - loss: 7.1428 - accuracy: 0.53 - ETA: 0s - loss: 7.1340 - accuracy: 0.53 - ETA: 0s - loss: 7.1466 - accuracy: 0.53 - ETA: 0s - loss: 7.1903 - accuracy: 0.53 - ETA: 0s - loss: 7.1919 - accuracy: 0.53 - ETA: 0s - loss: 7.2119 - accuracy: 0.53 - ETA: 0s - loss: 7.1941 - accuracy: 0.53 - ETA: 0s - loss: 7.2126 - accuracy: 0.53 - ETA: 0s - loss: 7.1788 - accuracy: 0.53 - 3s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 8/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 7.2304 - accuracy: 0.53 - ETA: 2s - loss: 8.1945 - accuracy: 0.46 - ETA: 2s - loss: 8.0017 - accuracy: 0.48 - ETA: 2s - loss: 7.2993 - accuracy: 0.52 - ETA: 1s - loss: 7.1233 - accuracy: 0.53 - ETA: 1s - loss: 6.9237 - accuracy: 0.55 - ETA: 1s - loss: 7.2304 - accuracy: 0.53 - ETA: 1s - loss: 7.2649 - accuracy: 0.52 - ETA: 1s - loss: 7.2304 - accuracy: 0.53 - ETA: 1s - loss: 7.2588 - accuracy: 0.52 - ETA: 1s - loss: 7.2051 - accuracy: 0.53 - ETA: 1s - loss: 7.2304 - accuracy: 0.53 - ETA: 1s - loss: 7.2933 - accuracy: 0.52 - ETA: 1s - loss: 7.2706 - accuracy: 0.52 - ETA: 1s - loss: 7.2675 - accuracy: 0.52 - ETA: 1s - loss: 7.2993 - accuracy: 0.52 - ETA: 1s - loss: 7.2947 - accuracy: 0.52 - ETA: 1s - loss: 7.3660 - accuracy: 0.52 - ETA: 0s - loss: 7.2446 - accuracy: 0.53 - ETA: 0s - loss: 7.2974 - accuracy: 0.52 - ETA: 0s - loss: 7.2558 - accuracy: 0.52 - ETA: 0s - loss: 7.2304 - accuracy: 0.53 - ETA: 0s - loss: 7.1501 - accuracy: 0.53 - ETA: 0s - loss: 7.1071 - accuracy: 0.53 - ETA: 0s - loss: 7.1340 - accuracy: 0.53 - ETA: 0s - loss: 7.1689 - accuracy: 0.53 - ETA: 0s - loss: 7.1616 - accuracy: 0.53 - ETA: 0s - loss: 7.1533 - accuracy: 0.53 - ETA: 0s - loss: 7.1285 - accuracy: 0.53 - ETA: 0s - loss: 7.1233 - accuracy: 0.53 - ETA: 0s - loss: 7.1340 - accuracy: 0.53 - ETA: 0s - loss: 7.1013 - accuracy: 0.53 - 3s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 9/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 8.6765 - accuracy: 0.43 - ETA: 2s - loss: 7.5518 - accuracy: 0.51 - ETA: 2s - loss: 8.0981 - accuracy: 0.47 - ETA: 1s - loss: 7.9879 - accuracy: 0.48 - ETA: 2s - loss: 7.6522 - accuracy: 0.50 - ETA: 2s - loss: 7.3376 - accuracy: 0.52 - ETA: 1s - loss: 7.2304 - accuracy: 0.53 - ETA: 1s - loss: 7.6383 - accuracy: 0.50 - ETA: 1s - loss: 7.5748 - accuracy: 0.50 - ETA: 1s - loss: 7.6221 - accuracy: 0.50 - ETA: 1s - loss: 7.5991 - accuracy: 0.50 - ETA: 1s - loss: 7.6110 - accuracy: 0.50 - ETA: 1s - loss: 7.6207 - accuracy: 0.50 - ETA: 1s - loss: 7.6077 - accuracy: 0.50 - ETA: 1s - loss: 7.5389 - accuracy: 0.51 - ETA: 1s - loss: 7.4804 - accuracy: 0.51 - ETA: 1s - loss: 7.4133 - accuracy: 0.51 - ETA: 1s - loss: 7.3704 - accuracy: 0.52 - ETA: 0s - loss: 7.3619 - accuracy: 0.52 - ETA: 0s - loss: 7.3682 - accuracy: 0.52 - ETA: 0s - loss: 7.3477 - accuracy: 0.52 - ETA: 0s - loss: 7.3953 - accuracy: 0.52 - ETA: 0s - loss: 7.3417 - accuracy: 0.52 - ETA: 0s - loss: 7.2892 - accuracy: 0.52 - ETA: 0s - loss: 7.3089 - accuracy: 0.52 - ETA: 0s - loss: 7.3376 - accuracy: 0.52 - ETA: 0s - loss: 7.2715 - accuracy: 0.52 - ETA: 0s - loss: 7.2796 - accuracy: 0.52 - ETA: 0s - loss: 7.2872 - accuracy: 0.52 - ETA: 0s - loss: 7.2768 - accuracy: 0.52 - ETA: 0s - loss: 7.2572 - accuracy: 0.52 - ETA: 0s - loss: 7.1788 - accuracy: 0.53 - 3s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n",
      "Epoch 10/10\n",
      "1845/1845 [==============================] - ETA: 2s - loss: 4.8203 - accuracy: 0.68 - ETA: 2s - loss: 6.5074 - accuracy: 0.57 - ETA: 2s - loss: 7.1099 - accuracy: 0.53 - ETA: 2s - loss: 6.9091 - accuracy: 0.55 - ETA: 2s - loss: 6.7484 - accuracy: 0.56 - ETA: 1s - loss: 6.9627 - accuracy: 0.54 - ETA: 1s - loss: 7.1866 - accuracy: 0.53 - ETA: 1s - loss: 6.8597 - accuracy: 0.55 - ETA: 1s - loss: 7.1019 - accuracy: 0.53 - ETA: 1s - loss: 7.0887 - accuracy: 0.54 - ETA: 1s - loss: 6.9767 - accuracy: 0.54 - ETA: 1s - loss: 7.0468 - accuracy: 0.54 - ETA: 1s - loss: 6.8532 - accuracy: 0.55 - ETA: 1s - loss: 6.9798 - accuracy: 0.54 - ETA: 1s - loss: 7.1055 - accuracy: 0.53 - ETA: 1s - loss: 7.0583 - accuracy: 0.54 - ETA: 1s - loss: 7.0376 - accuracy: 0.54 - ETA: 1s - loss: 7.0283 - accuracy: 0.54 - ETA: 0s - loss: 7.1720 - accuracy: 0.53 - ETA: 0s - loss: 7.0789 - accuracy: 0.54 - ETA: 0s - loss: 7.1132 - accuracy: 0.53 - ETA: 0s - loss: 7.1192 - accuracy: 0.53 - ETA: 0s - loss: 7.1246 - accuracy: 0.53 - ETA: 0s - loss: 7.1520 - accuracy: 0.53 - ETA: 0s - loss: 7.1126 - accuracy: 0.53 - ETA: 0s - loss: 7.1587 - accuracy: 0.53 - ETA: 0s - loss: 7.1813 - accuracy: 0.53 - ETA: 0s - loss: 7.1359 - accuracy: 0.53 - ETA: 0s - loss: 7.1577 - accuracy: 0.53 - ETA: 0s - loss: 7.1516 - accuracy: 0.53 - ETA: 0s - loss: 7.1205 - accuracy: 0.53 - 2s 1ms/sample - loss: 7.1231 - accuracy: 0.5382 - val_loss: 6.7192 - val_accuracy: 0.5644\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24a8f63d2c8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
